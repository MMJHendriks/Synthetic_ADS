---
title: "Synthetic data"
author: "Stijn van den Broek"
date: "02/05/2021"
output:
  html_document: default
  pdf_document: default
---

```{r, results='hide', message=FALSE, warning=FALSE}
library(ggplot2)
library(tidyverse)
library(magrittr)
library(corrplot)
library(mice)
library(furrr)
library(purrr)
library(broom)
library(caret)
library(mboost)
library(e1071)
```

## Reading the data

```{r}
data = read.csv('diabetes.csv')
data$Outcome = factor(data$Outcome, levels = c(0, 1))
```

## Setting the seed

```{r}
set.seed(123)
```

# Functions

The following functions are used throughout the document.

## Function for obtaining statistical properties

```{r}
statistical_properties = function(dataframe){
  stats = data.frame()
  for (i in seq(1, length(colnames(dataframe)), 1)) {
    column_data = as.numeric(dataframe[,i])
    term = colnames(dataframe)[i]
    mean = mean(column_data)
    standard_deviation = sd(column_data)
    skewness = skewness(column_data)
    kurtosis = kurtosis(column_data)
    standard_error = sd(column_data)/sqrt(length(column_data))
    row = data.frame(term = term, mean = mean, standard_deviation = standard_deviation, skewness = skewness, kurtosis = kurtosis, standard_error = standard_error)
    stats = rbind(stats, row)
  }
  return(stats)
}
```

## Function for plotting distributions

```{r}
dataset_distribution = function(dataframe, bins = 20) {
  ggplot(gather(dataframe), aes(as.numeric(value))) + 
    geom_histogram(bins = bins) + 
    facet_wrap(~key, scales = 'free_x')
}
```

## Synthesizing function and imputation methods

```{r}
cart = rep("cart", ncol(data))
names(cart) = colnames(data)

custom_method = c("cart", "pmm", "pmm", "pmm", "cart", "pmm", "cart", "cart", "logreg")
names(custom_method) = colnames(data)


synthesize = function(dataframe, method = custom_method, m = 5, nsim = 100) {
  method = method
  predict <- make.predictorMatrix(dataframe)
  syn = future_map(1:nsim, ~ { 
  dataframe %>% mice(m=m,
                    method = method,
                    predictorMatrix = predict,
                    where = matrix(TRUE, nrow(dataframe), ncol(dataframe)),
                    #cp = 1e-32,
                    minbucket = 3,
                    print = FALSE)
  }, .options=future_options(seed=as.integer(123)), .progress=T, .id = "syn")
  
  return(syn)
}
```

## Pooling function

```{r}
pool3.syn <- function(mira) {
  
  if(class(mira)[1] == "mira") { # if the input object is of class mira
    fitlist <- mira %$% analyses # extract the analyses from the mira object
  }
  else {
    fitlist <- mira              # and otherwise, just take the input list
  }
  
  vars <- fitlist[[1]] %>% coef() %>% names()
  
  m <- length(fitlist)           # number of imputations
  
  pooled <- fitlist %>% 
    map_dfr(broom::tidy) %>%
    group_by(term) %>%
    summarise(est     = mean(estimate),
              bm      = sum((estimate - est)^2) / (m - 1),
              ubar    = mean(std.error^2),
              var     = ubar + bm/m, # new variance estimate
              df      = (m - 1) * (1 + (ubar * m)/bm), # and new df estimate
              lower   = est - qt(.975, df) * sqrt(var),
              upper   = est + qt(.975, df) * sqrt(var), .groups = 'drop') %>%
    arrange(factor(term, levels = vars))
  pooled
}
```

## Confidence interval function

```{r}
ci_cov <- function(pooled, true_fit = NULL, coefs = NULL, vars = NULL) {
  set.seed(123)
  
  if (!is.null(true_fit)) {
    coefs <- coef(true_fit)
    vars   <- diag(vcov(true_fit))
  }
  
  nsim <- nrow(pooled) / length(unique(pooled$term))
  
  pooled %>% mutate(true_coef = rep(coefs, times = nsim),
                    true_var  = rep(vars, times = nsim),
                    cover     = lower < true_coef & true_coef < upper) %>%
    group_by(term) %>%
    summarise("True Est" = unique(true_coef),
              "Syn Est"  = mean(est),
              "Bias"     = mean(est - true_coef),
              "True SE"  = unique(sqrt(true_var)),
              "Syn SE"   = mean(sqrt(var)),
              "df"       = mean(df),
              "Lower"    = mean(lower),
              "Upper"    = mean(upper),
              "CIW"      = mean(upper - lower),
              "Coverage" = mean(cover), .groups = "drop")
}
```

## Prediction function

```{r}
predict_synth_or_true = function(data, model) {
  set.seed(123) #for reproducibility
  predicted_values = predict(object = model, newdata = data)
  true_values = data[,ncol(data)] #it just takes the values in the last column of the data frame so this is very prone to errors
  result = data.frame(true_value = factor(true_values, levels = c(0, 1)), predicted_value = factor(predicted_values, levels = c(0, 1)))

  return(result)
}
```

# The process of synthesizing

These are the steps for synthesizing and analyzing the data.

## 1. formulating an analysis model

```{r}
analysis_model = glm(Outcome~BMI+Glucose+Pregnancies, data = data, family = "binomial")
```

## 2. Running the analysis model on the data set to obtain the true data inference

```{r}
summary(analysis_model)
```

## 3. Obtaining the statistical properties of the true data set

```{r}
true_statistics = statistical_properties(data)
```

## 4. Plotting the distributions of the true data set

```{r}
dataset_distribution(data)
```

## 5a. Synthesizing the data

```{r, warning=FALSE}
synthesized = synthesize(data, method = cart, nsim = 100)
```

## 5b. Calculating the statistical properties of the synthetic sets

```{r, warning=FALSE}
all_synthetic_statistics = data.frame()
for (i in seq(1, length(synthesized), 1)) { #looping through each simulation
  imputation = synthesized[[i]]
  for (n in seq(1, imputation$m, 1)) { #looping through each imputation of the simulation
    syndata = complete(imputation, action = n)
    synthetic_statistics = statistical_properties(syndata)
    
    all_synthetic_statistics = rbind(all_synthetic_statistics, synthetic_statistics)
  }
}
```

## 5c. Running the analysis model on each of the synthetic sets

```{r}
all_synthetic_parameters = data.frame()
for (i in seq(1, length(synthesized), 1)) { #looping through each simulation
  imputation = synthesized[[i]]
  for (n in seq(1, imputation$m, 1)) { #looping through each imputation of the simulation
    syndata = complete(imputation, action = n)
    synthetic_parameters = glm(Outcome~BMI+Glucose+Pregnancies, data = syndata, family = "binomial") %>% tidy()
    all_synthetic_parameters = rbind(all_synthetic_parameters, synthetic_parameters)
  }
}
```

## 5d. Combining the statistics and parameters into single inferences

```{r, warning=FALSE}
single_synthetic_statistics = data.frame()
for (i in seq(1, length(unique(all_synthetic_statistics$term)))) {
  term_data = all_synthetic_statistics[all_synthetic_statistics$term == unique(all_synthetic_statistics$term)[i],] %>%
    sapply(mean)
  term_data$term = unique(all_synthetic_statistics$term)[i]
  term_data = data.frame(term_data)
  single_synthetic_statistics = rbind(single_synthetic_statistics, term_data)
}

single_synthetic_parameters = data.frame()
for (i in seq(1, length(unique(all_synthetic_parameters$term)))) {
  term_data = all_synthetic_parameters[all_synthetic_parameters$term == unique(all_synthetic_parameters$term)[i],] %>%
    sapply(mean)
  term_data$term = unique(all_synthetic_parameters$term)[i]
  term_data = data.frame(term_data)
  single_synthetic_parameters = rbind(single_synthetic_parameters, term_data)
}
```

## 5e & 5f. Combining half of the imputed set randomly with half of the true set for each of the m imputed sets & running a prediction model that predicts syn or true

```{r}
total_result = data.frame() #data frame in which the results of all sampled data will be stored
for (i in seq(1, length(synthesized), 1)) { #looping through each simulation
  imputation = synthesized[[i]]
  for (n in seq(1, imputation$m, 1)) { #looping through each imputation of the simulation

    syndata = complete(imputation, action = n)
    
    true_data = sample_n(data, (nrow(data)*0.5)) #sampling half of the original data
    true_data$Synth_or_true = 0 #setting the true data to 0
    
    synthetic_data = sample_n(syndata, (nrow(syndata)*0.5)) #sampling half of the synthetic data
    synthetic_data$Synth_or_true = 1 #setting the synthetic data to 1
    
    prediction_data = rbind(true_data, synthetic_data) #combining the two samples into a single data set
    prediction_data$Synth_or_true = factor(prediction_data$Synth_or_true, levels = c(0, 1))
    
    train_index = sample(seq_len(nrow(prediction_data)), size = floor(0.30 * nrow(prediction_data))) #creating a list of indices that will be the training data

    train = prediction_data[train_index,]
    test = prediction_data[-train_index,]
    
    prediction_model = train(Synth_or_true ~ ., data = train, method = "glm") #prediction model with method glm for classification

    result = predict_synth_or_true(test, prediction_model) #using the prediction function to get a data frame of true and predicted values
    total_result = rbind(total_result, result) #appending the data frame to the overarching data frame
  }
}

cfmatrix = confusionMatrix(total_result$predicted_value, total_result$true_value) #creating a confusion matrix
print(cfmatrix)
print(prediction_model)
```

## 5g. Pooling the model parameters

```{r}
pooled = map_dfr(synthesized, function(x) {
  x %$%
   glm(Outcome ~ BMI+Glucose+Pregnancies, family = 'binomial') %>%
  pool3.syn()
})
```

## 6a. Comparing the synthetic statistics and parameters with the true statistics and parameters

```{r}
true_parameters = data.frame(tidy(analysis_model))
statistics_difference = single_synthetic_statistics[,2:ncol(single_synthetic_statistics)] - true_statistics[,2:ncol(true_statistics)]
parameters_difference = single_synthetic_parameters[,2:ncol(single_synthetic_parameters)] - true_parameters[,2:ncol(true_parameters)]
statistics_difference$term = single_synthetic_statistics$term
parameters_difference$term = single_synthetic_parameters$term
statistics_difference = statistics_difference[,c(ncol(statistics_difference),1:(ncol(statistics_difference)-1))]
parameters_difference = parameters_difference[,c(ncol(parameters_difference),1:(ncol(parameters_difference)-1))]

print(statistics_difference)
print(parameters_difference)
```

## 6b. Plotting the distributions of the statistics and parameters

```{r, warning=FALSE}
repeat_distribution = function(dataframe) {
  for (i in seq(1, length(unique(dataframe$term)), 1)) {
    print(unique(dataframe$term)[i])
    print(dataset_distribution(dataframe[dataframe$term == unique(dataframe$term)[i],]))
  }
}

print("Statistics")
repeat_distribution(all_synthetic_statistics)
print("Parameters")
repeat_distribution(all_synthetic_parameters)
```

## 6c. Calculating the confidence interval coverages

```{r}
true_data = glm(Outcome~BMI+Glucose+Pregnancies, data = data, family = "binomial")

confidence_interval = ci_cov(pooled, true_fit = true_data)
print(confidence_interval)
```

