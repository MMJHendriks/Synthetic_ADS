---
title: "Synthesis"
author: "Stijn van den Broek"
date: "02/05/2021"
output: html_document
---

```{r}
library(ggplot2)
library(tidyverse)
library(magrittr)
library(mice)
library(furrr)
library(purrr)
library(broom)
library(caret)
```

## Reading the data

```{r}
data = read.csv('diabetes.csv')
data[,'Outcome'] = factor(data[,'Outcome'])
```

## Setting the seed

```{r}
set.seed(123)
```

## Synthesizing function and imputation methods

```{r}
cart = rep("cart", ncol(data))
names(cart) = colnames(data)

custom_method = c("cart", "pmm", "pmm", "pmm", "cart", "pmm", "cart", "cart", "logreg")
names(custom_method) = colnames(data)


synthesize = function(dataframe, method = custom_method, m = 5, nsim = 100) {
  method = method
  predict <- make.predictorMatrix(dataframe)
  syn = future_map(1:nsim, ~ { 
  dataframe %>% mice(m=m,
                    method = method,
                    predictorMatrix = predict,
                    where=matrix(TRUE, nrow(dataframe), ncol(dataframe)),
                    print=FALSE)
  }, .options=future_options(seed=as.integer(123)), .progress=T, .id = "syn")
  
  return(syn)
}
```

## Pooling function

```{r}
pool3.syn = function(mira) {
  
  if(class(mira)[1] == "mira") { # if the input object is of class mira
    fitlist <- mira %$% analyses # extract the analyses from the mira object
  }
  else {
    fitlist <- mira              # and otherwise, just take the input list
  }
  
  m <- length(fitlist)           # number of imputations
  
  pooled <- fitlist %>% 
    map_dfr(broom::tidy) %>%
    group_by(term) %>%
    summarise(est     = mean(estimate),
              bm      = sum((estimate - est)^2) / (m - 1),
              ubar    = mean(std.error^2),
              var     = ubar + bm/m, # new variance estimate
              df      = (m - 1) * (1 + (ubar * m)/bm), # and new df estimate
              lower   = est - qt(.975, df) * sqrt(var),
              upper   = est + qt(.975, df) * sqrt(var), .groups = 'drop')
  
  return(pooled)
}
```

## Confidence interval function

```{r}
ci_cov = function(pooled, true_fit = NULL, coefs = NULL, vars = NULL) {
  
  if (!is.null(true_fit)) {
    coefs = coef(true_fit)
    vars = diag(vcov(true_fit))
  }
  
  nsim = nrow(pooled) / length(coefs)
  
  pooled %>% mutate(true_coef = rep(coefs, nsim),
                    true_var  = rep(vars, nsim),
                    cover     = lower < true_coef & true_coef < upper) %>%
    group_by(term) %>%
    summarise("True Est" = unique(true_coef),
              "Syn Est"  = mean(est),
              "Bias"     = mean(est - true_coef),
              "True SE"  = unique(sqrt(true_var)),
              "Syn SE"   = mean(sqrt(var)),
              "df"       = mean(df),
              "Lower"    = mean(lower),
              "Upper"    = mean(upper),
              "CIW"      = mean(upper - lower),
              "Coverage" = mean(cover), .groups = "drop")
}
```

## Prediction function

```{r}
predict_synth_or_true = function(data, model) {
  set.seed(123) #for reproducibility
  predicted_values = predict(object = model, newdata = data)
  predicted_values[predicted_values<0.5] = 0
  predicted_values[predicted_values>=0.5] = 1
  predicted_values = predicted_values
  true_values = data[,ncol(data)]
  
  result = data.frame(true_value = factor(true_values, levels = c(0, 1)), predicted_value = factor(predicted_values, levels = c(0, 1)))

  return(result)
}
```

## 5a. Synthesizing the data

```{r}
synthesized = synthesize(data, nsim = 10)
```

## 5c. Running the analysis model on each of the synthetic sets

```{r}
synthetic_analysis = analysis_model(data = synthesized, print = FALSE, synthetic = TRUE) #function is found in Analysis_Stijn.rmd
```

## 5f. Run a prediction model that predicts syn or true

```{r}
#preparing data for prediction
total_result = data.frame()
for (i in seq(1, length(synthesized), 1)) {
  imputation = synthesized[[i]]
  for (n in seq(1, imputation$m, 1)) {
    syndata = complete(imputation, action = n)
    true_data_index = sample(c(1:nrow(data)), size = (nrow(data)*0.5))
    true_data = data[true_data_index, 1:ncol(data)]
    true_data$Synth_or_true = 1
    synthetic_data_index = sample(c(1:nrow(syndata)), size = (nrow(syndata)*0.5))
    synthetic_data = syndata[synthetic_data_index, 1:ncol(syndata)]
    synthetic_data$Synth_or_true = 0
    prediction_data = rbind(true_data, synthetic_data)
    prediction_model = glm(Synth_or_true~Pregnancies+Glucose+BloodPressure+SkinThickness+Insulin+BMI+DiabetesPedigreeFunction+Age+Outcome, data = prediction_data, family = "binomial")
    result = predict_synth_or_true(prediction_data, prediction_model)
    total_result = rbind(total_result, result)
  }
}

cfmatrix = confusionMatrix(total_result$predicted_value, total_result$true_value)
cfmatrix
```

## 5g. Pooling the model parameters over the sets and recording the accuracy

```{r}
pooled = map_dfr(synthesized, function(x) {
  x %$%
  glm(Outcome ~ Pregnancies + Glucose, family = 'binomial') %>%
  pool3.syn()
})
```

## 6e. Calculating the 95% coverage rates of the parameters

```{r}
true_model = glm(Outcome~Pregnancies+Glucose, data = data, family = "binomial")
confidence_interval = ci_cov(pooled, true_fit = true_model)
```
